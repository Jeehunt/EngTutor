#!/usr/bin/env python3
"""
–ú–∏–≥—Ä–∞—Ü–∏—è —Ä—É—Å—Å–∫–∏—Ö —Å–ª–æ–≤: –ø–µ—Ä–µ–≤–æ–¥ —Ç–µ–∫—Å—Ç–æ–≤ –≤ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π –∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ–ª–µ–π.

Usage:
  python -m scripts.migrate_russian_words
"""

import os
import sys
import re
import time
from app.database import get_session, init_models
from app.models import Word
from app.services.enrichment import _enrich_single_openai


def detect_russian_text(text: str) -> bool:
    return bool(text and re.search(r"[–∞-—è—ë]", text.lower()))


def migrate_russian_words() -> None:
    print("üöÄ –ù–∞—á–∏–Ω–∞—é –º–∏–≥—Ä–∞—Ü–∏—é —Ä—É—Å—Å–∫–∏—Ö —Å–ª–æ–≤...")
    init_models()
    session = next(get_session())
    try:
        russian_words = [w for w in session.query(Word).filter(Word.text.isnot(None)).all() if detect_russian_text(w.text)]
        if not russian_words:
            print("‚úÖ –†—É—Å—Å–∫–∏—Ö —Å–ª–æ–≤ –≤ –±–∞–∑–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
            return
        print(f"üìö –ù–∞–π–¥–µ–Ω–æ {len(russian_words)} —Ä—É—Å—Å–∫–∏—Ö —Å–ª–æ–≤ –¥–ª—è –º–∏–≥—Ä–∞—Ü–∏–∏")
        chunk_size = 5
        for i in range(0, len(russian_words), chunk_size):
            chunk = russian_words[i:i + chunk_size]
            print(f"\nüîÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –≥—Ä—É–ø–ø—É {(i // chunk_size) + 1}/{(len(russian_words) + chunk_size - 1) // chunk_size} ({len(chunk)} —Å–ª–æ–≤)")
            for word in chunk:
                try:
                    print(f"  üìù –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é: '{word.text}' (ID: {word.id})")
                    _enrich_single_openai(word.id, word.text, force_overwrite=True)
                    print(f"  ‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: '{word.text}'")
                except Exception as e:
                    print(f"  ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ '{word.text}': {e}")
                    continue
            if i + chunk_size < len(russian_words):
                print("  ‚è≥ –ü–∞—É–∑–∞ 10 —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –≥—Ä—É–ø–ø–æ–π...")
                time.sleep(10)
        print(f"\nüéâ –ú–∏–≥—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(russian_words)} —Å–ª–æ–≤")
        total_words = session.query(Word).count()
        english_words = [w for w in session.query(Word).filter(Word.text.isnot(None)).all() if not detect_russian_text(w.text)]
        print("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ—Å–ª–µ –º–∏–≥—Ä–∞—Ü–∏–∏:")
        print(f"  –í—Å–µ–≥–æ —Å–ª–æ–≤: {total_words}")
        print(f"  –ê–Ω–≥–ª–∏–π—Å–∫–∏—Ö —Å–ª–æ–≤: {len(english_words)}")
        print(f"  –†—É—Å—Å–∫–∏—Ö —Å–ª–æ–≤: {total_words - len(english_words)}")
    finally:
        session.close()


if __name__ == "__main__":
    if not os.getenv("OPENAI_API_KEY"):
        print("‚ùå –û—à–∏–±–∫–∞: OPENAI_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        sys.exit(1)
    if not os.getenv("DATABASE_URL"):
        print("‚ùå –û—à–∏–±–∫–∞: DATABASE_URL –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        sys.exit(1)
    print("üîß –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è...")
    print(f"  DATABASE_URL: {'‚úÖ' if os.getenv('DATABASE_URL') else '‚ùå'}")
    print(f"  OPENAI_API_KEY: {'‚úÖ' if os.getenv('OPENAI_API_KEY') else '‚ùå'}")
    migrate_russian_words()


